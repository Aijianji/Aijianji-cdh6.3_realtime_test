#### 第十天

```
今天主要是在昨天搭的cdh集群上进行了两个测试
并且是基于更标准的框架结构写的代码
1.flink部署jar包到yarn运行
2.flinkcdc读取mysql数据并发送至kafka

遇到的问题
主要是依赖问题
还有就是不要在大项目名下面的java里写代码(例如:testCdc)，后续如果有子模块了，如果重名了，没有绝对路径，人家不知道去哪里找。
所以，建完项目直接把自带的src删掉，要写就去建子模块写去。

找不到类或者加载路径这种问题就还是之前的解决办法，maven那个，add dependencies with "provided" scope...前打勾

cdc读取数据并发送的那个测试如果报错说不能创建kafka生产者的错，就
https://blog.csdn.net/qq_26502245/article/details/114594526
```

```
晚上院长提问我关于flinkcdc
如果中间断了 后续会继续传还是从头传?
其实就是flink断点续传问题
(所有的断点续传都一样)，通过offset记录数据偏移量，然后存到文件里，下次从那个文件那里继续读，checkpoint以文件的形式存在hdfs中。
另一种是oos(向上存储)
指的是将数据从本地设备或较低层次的存储向云端的 OSS（Object Storage Service）等存储服务进行存储的过程。
因为有时候会因为网络波动或是文件过大导致传输中断，就得用断点续传了。提高文件传输的可靠性和效率，避免资源浪费。
```

